{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
      "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"/tmp/data/\", one_hot=True, validation_size=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "def timestamp():\n",
    "    d = datetime.datetime.now()\n",
    "    return d.strftime(\"%Y/%m/%d/%X\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "learning_rate = 0.5\n",
    "training_epochs = 25\n",
    "batch_size = 100\n",
    "display_step = 1\n",
    "pkeep = 0.75\n",
    "logs_path_train = '/tmp/tensorflow_logs/example/train' + timestamp()\n",
    "logs_path_val = '/tmp/tensorflow_logs/example/val' + timestamp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Placeholders\n",
    "x = tf.placeholder(tf.float32, [None, 784], name='InputData')\n",
    "y_ = tf.placeholder(tf.float32, [None, 10], name='LabelData')\n",
    "\n",
    "# Probability of keeping a node during dropout = 1.0 at \n",
    "# test time (no dropout)  and 0.75 at training time\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "\n",
    "# Variables\n",
    "W1 = tf.Variable(tf.truncated_normal([784, 200], stddev=0.1), name='Weights') \n",
    "b1 = tf.Variable(tf.zeros([200]), name='Bias')\n",
    "W2 = tf.Variable(tf.truncated_normal([200, 100], stddev=0.1), name='Weights')\n",
    "b2 = tf.Variable(tf.zeros([100]), name='Bias')\n",
    "W3 = tf.Variable(tf.truncated_normal([100, 60], stddev=0.1), name='Weights')\n",
    "b3 = tf.Variable(tf.zeros([60]), name='Bias')\n",
    "W4 = tf.Variable(tf.truncated_normal([60, 30], stddev=0.1), name='Weights')\n",
    "b4 = tf.Variable(tf.zeros([30]), name='Bias')\n",
    "W5 = tf.Variable(tf.truncated_normal([30, 10], stddev=0.1), name='Weights')\n",
    "b5 = tf.Variable(tf.zeros([10]), name='Bias')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Construct model and encapsulating all ops into scopes, making\n",
    "# Tensorboard's Graph visualization more convenient\n",
    "with tf.name_scope('Model'):\n",
    "    with tf.variable_scope('Dense1'):\n",
    "        y1 = tf.nn.relu(tf.matmul(x, W1) + b1)\n",
    "        y1d = tf.nn.dropout(y1, keep_prob)\n",
    "    y2 = tf.nn.relu(tf.matmul(y1, W2) + b2)\n",
    "    y2d = tf.nn.dropout(y2, keep_prob)\n",
    "    y3 = tf.nn.relu(tf.matmul(y2, W3) + b3)\n",
    "    y3d = tf.nn.dropout(y3, keep_prob)\n",
    "    y4 = tf.nn.relu(tf.matmul(y3, W4) + b4)\n",
    "    y4d = tf.nn.dropout(y4, keep_prob)\n",
    "    # predicted class (logits)\n",
    "    y = tf.matmul(y4, W5) + b5\n",
    "    \n",
    "with tf.name_scope('Loss'):\n",
    "    cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y_, logits=y))\n",
    "    \n",
    "with tf.name_scope('GD'):\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(cross_entropy)\n",
    "    \n",
    "with tf.name_scope('Accuracy'):\n",
    "    correct_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(y_, 1))\n",
    "    acc = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Initializing the variables\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create a summary to monitor cost tensor\n",
    "tf.summary.scalar(\"loss\", cross_entropy)\n",
    "# Create a summary to monitor accuracy tensor\n",
    "tf.summary.scalar(\"accuracy\", acc)\n",
    "# Merge all summaries into a single op\n",
    "merged_summary_op = tf.summary.merge_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001 train loss 0.652461598 val loss 0.630094816\n",
      "Epoch: 0002 train loss 0.148699215 val loss 0.139448482\n",
      "Epoch: 0003 train loss 0.098912121 val loss 0.104075240\n",
      "Epoch: 0004 train loss 0.076964023 val loss 0.099407430\n",
      "Epoch: 0005 train loss 0.067597776 val loss 0.098150976\n",
      "Epoch: 0006 train loss 0.050906090 val loss 0.088968713\n",
      "Epoch: 0007 train loss 0.040171719 val loss 0.088300583\n",
      "Epoch: 0008 train loss 0.033935658 val loss 0.090620353\n",
      "Epoch: 0009 train loss 0.025873286 val loss 0.086285626\n",
      "Epoch: 0010 train loss 0.024036739 val loss 0.095548699\n",
      "Epoch: 0011 train loss 0.023523512 val loss 0.093903545\n",
      "Epoch: 0012 train loss 0.018410850 val loss 0.092338703\n",
      "Epoch: 0013 train loss 0.017628225 val loss 0.099352712\n",
      "Epoch: 0014 train loss 0.011537100 val loss 0.100468856\n",
      "Epoch: 0015 train loss 0.016723401 val loss 0.099414934\n",
      "Epoch: 0016 train loss 0.012784172 val loss 0.107679026\n",
      "Epoch: 0017 train loss 0.012715905 val loss 0.106181372\n",
      "Epoch: 0018 train loss 0.009957719 val loss 0.107947681\n",
      "Epoch: 0019 train loss 0.010267099 val loss 0.110946810\n",
      "Epoch: 0020 train loss 0.014227518 val loss 0.110653451\n",
      "Epoch: 0021 train loss 0.007603280 val loss 0.104176057\n",
      "Epoch: 0022 train loss 0.007051167 val loss 0.103757224\n",
      "Epoch: 0023 train loss 0.005097549 val loss 0.101606049\n",
      "Epoch: 0024 train loss 0.002152348 val loss 0.100880608\n",
      "Epoch: 0025 train loss 0.001143017 val loss 0.105063316\n",
      "Optimization Finished!\n",
      "Accuracy: 0.9823\n",
      "Accuracy: 0.9823\n",
      "Run the command line:\n",
      "--> tensorboard --logdir=/tmp/tensorflow_logs \n",
      "Then open http://0.0.0.0:6006/\n"
     ]
    }
   ],
   "source": [
    "# Launch the graph\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "\n",
    "    # op to write logs to Tensorboard\n",
    "    summary_writer_train = tf.summary.FileWriter(logs_path_train, graph=tf.get_default_graph())\n",
    "    summary_writer_val = tf.summary.FileWriter(logs_path_val, graph=tf.get_default_graph())\n",
    "\n",
    "    # Training cycle\n",
    "    for epoch in range(training_epochs):\n",
    "        avg_train_loss = 0.\n",
    "        avg_val_loss = 0.\n",
    "        total_batch = int(mnist.train.num_examples / batch_size)\n",
    "          \n",
    "        # Loop over all batches\n",
    "        for i in range(total_batch):\n",
    "            batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "            batch_x_val, batch_y_val = mnist.validation.next_batch(batch_size)\n",
    "\n",
    "            # Run optimization op (backprop), cost op (to get loss value)\n",
    "            # and summary nodes\n",
    "            a, c, summary = sess.run([optimizer, cross_entropy, merged_summary_op], \n",
    "                                     feed_dict={x: batch_xs, y_: batch_ys, \n",
    "                                                keep_prob: pkeep}) \n",
    "            \n",
    "            c_val, summary_val = sess.run([cross_entropy, merged_summary_op], \n",
    "                                                    feed_dict={x: batch_x_val, \n",
    "                                                               y_: batch_y_val}) \n",
    "\n",
    "            # Write logs at every iteration\n",
    "            summary_writer_train.add_summary(summary, epoch * total_batch + i)\n",
    "            summary_writer_val.add_summary(summary_val, epoch * total_batch + i)\n",
    "\n",
    "            # Compute average loss\n",
    "            avg_train_loss += c / total_batch\n",
    "            avg_val_loss += c_val / total_batch\n",
    "            \n",
    "        # Display logs per epoch step\n",
    "        if (epoch + 1) % display_step == 0:\n",
    "            print(\"Epoch:\", '%04d' % (epoch + 1),\n",
    "                  \"train loss\", \"{:.9f}\".format(avg_train_loss),\n",
    "                  \"val loss\", \"{:.9f}\".format(avg_val_loss))\n",
    "\n",
    "    print(\"Optimization Finished!\")\n",
    "\n",
    "    # Test model\n",
    "    # Calculate accuracy    \n",
    "    total_test_batch = mnist.test.num_examples // batch_size    \n",
    "    acc_test_lst = []\n",
    "    for step in range(mnist.test.images.shape[0] // total_test_batch):        \n",
    "        acc_test = acc.eval(\n",
    "            {x: mnist.test.images[step * total_test_batch:(step + 1) * total_test_batch, :], \n",
    "             y_: mnist.test.labels[step * total_test_batch:(step + 1) * total_test_batch, :]}) \n",
    "        acc_test_lst.append(acc_test)\n",
    "    print(\"Accuracy:\", np.mean(acc_test_lst))    \n",
    "    print(\"Accuracy:\", acc.eval({x: mnist.test.images, y_: mnist.test.labels}))\n",
    "\n",
    "    print(\"Run the command line:\\n\" \\\n",
    "          \"--> tensorboard --logdir=/tmp/tensorflow_logs \" \\\n",
    "          \"\\nThen open http://0.0.0.0:6006/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
