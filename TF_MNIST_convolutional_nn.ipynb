{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/train-images-idx3-ubyte.gz\n",
      "Extracting data/train-labels-idx1-ubyte.gz\n",
      "Extracting data/t10k-images-idx3-ubyte.gz\n",
      "Extracting data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import math\n",
    "from tensorflow.contrib.learn.python.learn.datasets.mnist import read_data_sets\n",
    "mnist = read_data_sets(\"data\", one_hot=True, reshape=False, validation_size=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "def timestamp():\n",
    "    d = datetime.datetime.now()\n",
    "    return d.strftime(\"%Y/%m/%d/%X\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "training_epochs = 25\n",
    "learning_rate = 0.001\n",
    "batch_size = 100\n",
    "display_step = 1\n",
    "logs_path_train = '/tmp/tensorflow_logs/example/train' + timestamp()\n",
    "logs_path_val = '/tmp/tensorflow_logs/example/val' + timestamp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Placeholders\n",
    "x = tf.placeholder(tf.float32, [None, 28, 28, 1])\n",
    "y_ = tf.placeholder(tf.float32, [None, 10])\n",
    "\n",
    "# Variables\n",
    "W1 = tf.Variable(tf.truncated_normal([5, 5, 1, 4], stddev=0.1))\n",
    "b1 = tf.Variable(tf.ones([4]))\n",
    "W2 = tf.Variable(tf.truncated_normal([5, 5, 4, 8], stddev=0.1))\n",
    "b2 = tf.Variable(tf.ones([8]))\n",
    "W3 = tf.Variable(tf.truncated_normal([4, 4, 8, 12], stddev=0.1))\n",
    "b3 = tf.Variable(tf.ones([12]))\n",
    "W4 = tf.Variable(tf.truncated_normal([7 * 7 * 12, 200], stddev=0.1))\n",
    "b4 = tf.Variable(tf.ones([200]))\n",
    "W5 = tf.Variable(tf.truncated_normal([200, 10], stddev=0.1))\n",
    "b5 = tf.Variable(tf.ones([10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The model\n",
    "stride = 1  # output is 28x28\n",
    "y1 = tf.nn.relu(tf.nn.conv2d(x, W1, strides=[1, stride, stride, 1], padding='SAME') + b1)\n",
    "stride = 2  # output is 14x14\n",
    "y2 = tf.nn.relu(tf.nn.conv2d(y1, W2, strides=[1, stride, stride, 1], padding='SAME') + b2)\n",
    "stride = 2  # output is 7x7\n",
    "y3 = tf.nn.relu(tf.nn.conv2d(y2, W3, strides=[1, stride, stride, 1], padding='SAME') + b3)\n",
    "\n",
    "# reshape the output from the third convolution for the fully connected layer\n",
    "y3_conv = tf.reshape(y3, shape=[-1, 7 * 7 * 12])\n",
    "\n",
    "y4 = tf.nn.relu(tf.matmul(y3_conv, W4) + b4)\n",
    "y = tf.matmul(y4, W5) + b5\n",
    "\n",
    "with tf.name_scope('Loss'):\n",
    "    cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=y, labels=y_))\n",
    "\n",
    "with tf.name_scope('Optimizer'):\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate).minimize(cross_entropy)\n",
    "    \n",
    "with tf.name_scope('Accuracy'):\n",
    "    correct_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(y_, 1))\n",
    "    acc = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Initializing the variables\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create a summary to monitor cost tensor\n",
    "tf.summary.scalar(\"loss\", cross_entropy)\n",
    "# Create a summary to monitor accuracy tensor\n",
    "tf.summary.scalar(\"accuracy\", acc)\n",
    "# Merge all summaries into a single op\n",
    "merged_summary_op = tf.summary.merge_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001 train loss 0.519030024 val loss 0.490417672\n",
      "Epoch: 0002 train loss 0.139758559 val loss 0.128451929\n",
      "Epoch: 0003 train loss 0.087371599 val loss 0.084609371\n",
      "Epoch: 0004 train loss 0.061804112 val loss 0.068177679\n",
      "Epoch: 0005 train loss 0.049285247 val loss 0.062701552\n",
      "Epoch: 0006 train loss 0.041229983 val loss 0.058394420\n",
      "Epoch: 0007 train loss 0.033098495 val loss 0.057881123\n",
      "Epoch: 0008 train loss 0.028011630 val loss 0.055775380\n",
      "Epoch: 0009 train loss 0.021774917 val loss 0.057643177\n",
      "Epoch: 0010 train loss 0.020834223 val loss 0.058370087\n",
      "Epoch: 0011 train loss 0.017774762 val loss 0.054346654\n",
      "Epoch: 0012 train loss 0.014144538 val loss 0.057289973\n",
      "Epoch: 0013 train loss 0.013036005 val loss 0.058730355\n",
      "Epoch: 0014 train loss 0.013827116 val loss 0.062303040\n",
      "Epoch: 0015 train loss 0.010177226 val loss 0.060663916\n",
      "Epoch: 0016 train loss 0.009066836 val loss 0.062783316\n",
      "Epoch: 0017 train loss 0.011169695 val loss 0.066249867\n",
      "Epoch: 0018 train loss 0.007604376 val loss 0.067423702\n",
      "Epoch: 0019 train loss 0.006111505 val loss 0.064887133\n",
      "Epoch: 0020 train loss 0.008089416 val loss 0.072633549\n",
      "Epoch: 0021 train loss 0.008299767 val loss 0.069992524\n",
      "Epoch: 0022 train loss 0.006240912 val loss 0.063203702\n",
      "Epoch: 0023 train loss 0.003480245 val loss 0.060014184\n",
      "Epoch: 0024 train loss 0.007399569 val loss 0.077327504\n",
      "Epoch: 0025 train loss 0.006578658 val loss 0.075452639\n",
      "Optimization Finished!\n",
      "total_test_batch 100\n",
      "Accuracy: 0.9876\n",
      "Run the command line:\n",
      "--> tensorboard --logdir=/tmp/tensorflow_logs \n",
      "Then open http://0.0.0.0:6006/\n"
     ]
    }
   ],
   "source": [
    "# Launch the graph\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "\n",
    "    # op to write logs to Tensorboard\n",
    "    summary_writer_train = tf.summary.FileWriter(logs_path_train, \n",
    "                                                 graph=tf.get_default_graph())\n",
    "    summary_writer_val = tf.summary.FileWriter(logs_path_val, \n",
    "                                               graph=tf.get_default_graph())\n",
    "\n",
    "    # Training cycle\n",
    "    for epoch in range(training_epochs):\n",
    "        avg_train_loss = 0.\n",
    "        avg_val_loss = 0.\n",
    "        total_batch = int(mnist.train.num_examples / batch_size)\n",
    "          \n",
    "        # Loop over all batches\n",
    "        for i in range(total_batch):\n",
    "            batch_x_train, batch_y_train = mnist.train.next_batch(batch_size)\n",
    "            batch_x_val, batch_y_val = mnist.validation.next_batch(batch_size)\n",
    "            \n",
    "            # Run optimization op (backprop), cost op (to get loss value) and summary nodes\n",
    "            # and summary nodes\n",
    "            a, c, summary = sess.run([optimizer, cross_entropy, merged_summary_op], \n",
    "                                     feed_dict={x: batch_x_train, \n",
    "                                                y_: batch_y_train})            \n",
    "            \n",
    "            c_val, summary_val = sess.run([cross_entropy, merged_summary_op], \n",
    "                                          feed_dict={x: batch_x_val, \n",
    "                                                     y_: batch_y_val}) \n",
    "\n",
    "            # Write logs at every iteration\n",
    "            summary_writer_train.add_summary(summary, epoch * total_batch + i)\n",
    "            summary_writer_val.add_summary(summary_val, epoch * total_batch + i)\n",
    "\n",
    "            # Compute average loss\n",
    "            avg_train_loss += c / total_batch\n",
    "            avg_val_loss += c_val / total_batch\n",
    "            \n",
    "        # Display logs per epoch step\n",
    "        if (epoch + 1) % display_step == 0:\n",
    "            print(\"Epoch:\", '%04d' % (epoch + 1),\n",
    "                  \"train loss\", \"{:.9f}\".format(avg_train_loss),\n",
    "                  \"val loss\", \"{:.9f}\".format(avg_val_loss))\n",
    "\n",
    "    print(\"Optimization Finished!\")\n",
    "\n",
    "    # Test model\n",
    "    # Calculate accuracy    \n",
    "    total_test_batch = mnist.test.num_examples // batch_size\n",
    "    print('total_test_batch', total_test_batch)    \n",
    "    acc_test_lst = []\n",
    "    for step in range(mnist.test.images.shape[0] // total_test_batch):        \n",
    "        acc_test = acc.eval(\n",
    "            {x: mnist.test.images[step * total_test_batch:(step + 1) * total_test_batch, :], \n",
    "             y_: mnist.test.labels[step * total_test_batch:(step + 1) * total_test_batch, :]}) \n",
    "        acc_test_lst.append(acc_test)    \n",
    "    print(\"Accuracy:\", np.mean(acc_test_lst))\n",
    "\n",
    "    print(\"Run the command line:\\n\" \\\n",
    "          \"--> tensorboard --logdir=/tmp/tensorflow_logs \" \\\n",
    "          \"\\nThen open http://0.0.0.0:6006/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
